import os
import shutil
import hashlib
import difflib
from pathlib import Path
from datetime import datetime
import argparse

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Paths
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

PROJECT_ROOT = Path(__file__).resolve().parent
TEMPLATE_ROOT = PROJECT_ROOT / "hardening_content" / "templates"
LOG_PATH = PROJECT_ROOT / "logs" / "hardener.log"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Canonical Template Map
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Maps repo-relative paths â†’ template-relative paths

FILES_FROM_TEMPLATES = [
    ("app/main.py", "app/main.py"),
    ("app/core/metrics.py", "app/core/metrics.py"),
    ("app/api/auth_routes.py", "app/api/auth_routes.py"),
    ("infra/monitoring/prometheus-rules.yaml", "infra/monitoring/prometheus-rules.yaml"),
    ("infra/monitoring/grafana-dashboard.json", "infra/monitoring/grafana-dashboard.json"),
]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Logging
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def log(msg: str):
    LOG_PATH.parent.mkdir(parents=True, exist_ok=True)
    from datetime import datetime, timezone
    timestamp = datetime.now(timezone.utc).isoformat()
    entry = f"[{timestamp}] {msg}"
    with LOG_PATH.open("a", encoding="utf-8") as f:
        f.write(entry + "\n")
    print(entry)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Hashing
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def file_hash(path: Path) -> str:
    if not path.exists():
        return "<missing>"
    h = hashlib.sha256()
    with path.open("rb") as f:
        h.update(f.read())
    return h.hexdigest()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Backup / Restore
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def backup_once(path: Path):
    if not path.exists():
        return
    backup_path = path.with_suffix(path.suffix + ".bak")
    if backup_path.exists():
        return
    shutil.copy2(path, backup_path)
    log(f"[BACKUP] {path} -> {backup_path}")

def rollback_all():
    for bak in PROJECT_ROOT.rglob("*.bak"):
        original = bak.with_suffix("")
        shutil.copy2(bak, original)
        log(f"[ROLLBACK] Restored {original} from {bak}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Diff
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def show_diff(old: str, new: str, path: Path):
    diff = difflib.unified_diff(
        old.splitlines(),
        new.splitlines(),
        fromfile=str(path),
        tofile=str(path),
        lineterm=""
    )
    for line in diff:
        print(line)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Template Loader
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def load_template(template_rel: str) -> str:
    template_path = TEMPLATE_ROOT / template_rel
    if not template_path.exists():
        raise FileNotFoundError(f"Missing template: {template_path}")
    return template_path.read_text(encoding="utf-8")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Harden from Template
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def write_hardened_from_template(repo_rel: str, template_rel: str, dry_run=False):
    out_path = PROJECT_ROOT / repo_rel
    content = load_template(template_rel)

    banner = (
        "# ðŸ”± Autoâ€‘generated by Veil Sentinel Hardener\n"
        "# Do not edit manually â€” changes will be overwritten.\n\n"
    )
    final = banner + content

    out_path.parent.mkdir(parents=True, exist_ok=True)

    old_content = out_path.read_text(encoding="utf-8") if out_path.exists() else ""

    if old_content == final:
        log(f"[SKIP] {repo_rel}: no changes")
        return

    log(f"[DIFF] {repo_rel}")
    show_diff(old_content, final, out_path)

    if dry_run:
        log(f"[DRYâ€‘RUN] Would write {out_path}")
        return

    backup_once(out_path)
    out_path.write_text(final, encoding="utf-8")
    log(f"[WRITE] {repo_rel}: {out_path}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Harden entire /docs directory
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def harden_docs_folder(docs_root: Path, dry_run=False):
    banner = (
        "# ðŸ”± Autoâ€‘generated by Veil Sentinel Hardener\n"
        "# Do not edit manually â€” changes will be overwritten.\n\n"
    )

    for path in docs_root.rglob("*"):
        if path.is_dir():
            continue
        if path.suffix == ".bak":
            continue
        if path.suffix.lower() in [
            ".png", ".jpg", ".jpeg", ".gif", ".ico",
            ".svg", ".ttf", ".woff", ".woff2"
        ]:
            continue

        try:
            old_content = path.read_text(encoding="utf-8")
        except Exception:
            log(f"[SKIP] Binary or unreadable file: {path}")
            continue

        new_content = banner + old_content

        if old_content == new_content:
            log(f"[SKIP] {path}: already hardened")
            continue

        log(f"[DIFF] Hardening {path}")
        show_diff(old_content, new_content, path)

        if dry_run:
            log(f"[DRYâ€‘RUN] Would harden {path}")
            continue

        backup_once(path)
        path.write_text(new_content, encoding="utf-8")
        log(f"[WRITE] Hardened {path}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Docs Language Hardener (Updater â†’ Hardener)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def harden_docs_language(docs_root: Path, dry_run=False):
    for path in docs_root.rglob("*.md"):
        old = path.read_text(encoding="utf-8")
        new = old.replace("Updater", "Hardener")

        if old == new:
            continue

        log(f"[DIFF] Language update in {path}")
        show_diff(old, new, path)

        if dry_run:
            log(f"[DRYâ€‘RUN] Would update language in {path}")
            continue

        backup_once(path)
        path.write_text(new, encoding="utf-8")
        log(f"[WRITE] Updated language in {path}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Recursive __init__.py creation
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def ensure_init_recursive(root: Path, dry_run=False):
    for dirpath, dirnames, filenames in os.walk(root):
        dirpath = Path(dirpath)

        if dirpath.name.startswith(".") or dirpath.name == "__pycache__":
            continue

        init_path = dirpath / "__init__.py"

        if init_path.exists():
            backup_once(init_path)
            continue

        content = f'"""Hardened package initializer for {dirpath.name}."""\n'

        if dry_run:
            log(f"[DRYâ€‘RUN] Would create {init_path}")
        else:
            init_path.write_text(content, encoding="utf-8")
            log(f"[INIT] Created {init_path}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Canonical Drift Detector
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

CANONICAL_ZONES = [
    PROJECT_ROOT / "app",
    PROJECT_ROOT / "infra",
]

def detect_drift(dry_run: bool = False):
    log("â”€â”€ Drift Detector: Scanning for canonical mismatches")

    declared_canonicals = {Path(repo_rel) for repo_rel, _ in FILES_FROM_TEMPLATES}

    # 1. Missing canonical files
    for repo_rel, template_rel in FILES_FROM_TEMPLATES:
        out_path = PROJECT_ROOT / repo_rel
        if not out_path.exists():
            log(f"[DRIFT] Missing canonical file: {out_path}")

    # 2. Templates with no output file
    for repo_rel, template_rel in FILES_FROM_TEMPLATES:
        template_path = TEMPLATE_ROOT / template_rel
        out_path = PROJECT_ROOT / repo_rel
        if template_path.exists() and not out_path.exists():
            log(f"[DRIFT] Template exists but output file missing: {repo_rel}")

    # 3. Undeclared files in canonical zones
    for zone in CANONICAL_ZONES:
        if not zone.exists():
            continue
        for path in zone.rglob("*"):
            if path.is_dir():
                continue
            if path.suffix == ".bak":
                continue

            repo_rel = path.relative_to(PROJECT_ROOT)

            if repo_rel not in declared_canonicals:
                log(f"[DRIFT] Undeclared file in canonical zone: {repo_rel}")
                log("        â†’ Consider templating this file or marking it non-canonical.")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Main Hardening Flow
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--dry-run", action="store_true")
    parser.add_argument("--rollback", action="store_true")
    args = parser.parse_args()

    if args.rollback:
        rollback_all()
        return

    dry = args.dry_run

    log("ðŸ”± Starting Veil Sentinel Hardening Pass")

    # Phase 1
    log("â”€â”€ Phase 1: Ensuring package structure (__init__.py)")
    ensure_init_recursive(PROJECT_ROOT / "app", dry_run=dry)
    ensure_init_recursive(PROJECT_ROOT / "infra", dry_run=dry)

    # Phase 2
    log("â”€â”€ Phase 2: Hardening core files from templates")
    for repo_rel, template_rel in FILES_FROM_TEMPLATES:
        write_hardened_from_template(repo_rel, template_rel, dry_run=dry)

    # Phase 3
    log("â”€â”€ Phase 3: Hardening docs banners")
    harden_docs_folder(PROJECT_ROOT / "docs", dry_run=dry)

    # Phase 4
    log("â”€â”€ Phase 4: Hardening docs language (Updater â†’ Hardener)")
    harden_docs_language(PROJECT_ROOT / "docs", dry_run=dry)

    # Phase 5
    log("â”€â”€ Phase 5: Drift Detection")
    detect_drift(dry_run=dry)

    log("ðŸ”± Hardening complete")

if __name__ == "__main__":
    main()
